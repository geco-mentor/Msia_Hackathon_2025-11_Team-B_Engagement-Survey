import os
from openai import OpenAI
import pandas as pd
import json
from typing import List, Optional
from huggingface_hub import login
from dotenv import load_dotenv
from pydantic import BaseModel, Field
import malaya
import inspect

# Fix for Malaya compatibility
if not hasattr(inspect, 'getargspec'):
    inspect.getargspec = inspect.getfullargspec

load_dotenv()

# Initialize OpenAI client for Ollama
client = OpenAI(
    base_url="http://localhost:11434/v1", 
    api_key="ollama" 
)

# HuggingFace login
hf_token = os.environ.get('HF_TOKEN')
if hf_token:
    login(hf_token, add_to_git_credential=True)


# ==================== Pydantic Models ====================

class ExtractionResponse(BaseModel):
    """Model for keyword and category extraction response"""
    categories: str = Field(
        default="", 
        description="High-level categories or themes (e.g., service, product, complaint, praise)"
    )


class SentimentResponse(BaseModel):
    """Model for sentiment evaluation response"""
    sentiment_score: int = Field(
        ..., 
        ge=1, 
        le=10,
        description="Sentiment score from 1 (extremely negative) to 10 (very positive)"
    )
    sentiment_label: str = Field(
        ...,
        description="Sentiment classification: negative, neutral, or positive"
    )


class CommentAnalysis(BaseModel):
    """Model for complete comment analysis output"""
    original: str = Field(..., description="Original comment in Malay/Manglish")
    rephrased: str = Field(..., description="Rephrased professional English version")
    categories: str = Field(
        default="", 
        description="Identified categories"
    )
    sentiment_score: int = Field(
        default=5, 
        description="Sentiment score from 1 (extremely negative) to 10 (very positive)"
    )
    sentiment_label: str = Field(
        default="neutral",
        description="Sentiment classification: negative, neutral, or positive"
    )


# ==================== Helper Functions ====================

def get_sentiment_label(sentiment_score: int) -> str:
    """
    Convert sentiment score to categorical label.
    """
    if sentiment_score <= 4:
        return "negative"
    elif sentiment_score <= 6:
        return "neutral"
    else:
        return "positive"

# ==================== AI Functions (Forward Declarations) ====================

def ai_rephrase(original_comment: str, translated_comment: str) -> str:
    """
    Uses AI to rephrase the comment professionally while maintaining meaning.
    """
    prompt = f"""You are a professional text editor as a Malaysian. Given an original comment in Malay/Manglish and its machine translation, rewrite the comment into clear, natural, professional English. Preserve the exact meaning and sentiment. Do NOT add or remove any information.
    
Original: "{original_comment}"
Translation: "{translated_comment}"

Output ONLY the refined English version.
"""

    try:
        response = client.chat.completions.create(
            model="llama3.2",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=150,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        # Fallback to translated version if AI fails
        return translated_comment


def ai_extract_categories(comment: str) -> ExtractionResponse:
    """
    Uses AI to identify categories from a comment.
    """
    prompt = f""" You are a professional HR analyst.
Analyze the following employee comment and generate 1 high-level CATEGORY that best describes the main theme expressed by the employee.

The categories should:
- Be abstract, high-level themes (e.g., "service quality", "work environment", "leadership", "communication issues", "process inefficiency", etc.)
- Be derived entirely from the content of the comment.
- NOT be restricted to any predefined list.
- Capture the main topic or concern/compliment highlighted in the comment.
- Be concise and specific that GOOD or BAD.

Comment: "{comment}"

Respond in JSON format with one field:
- "categories": string with exactly 1 category (e.g., "Workload & Capacity", "Leadership Trust", "Career Development", "Team Collaboration", "Work-Life Balance")

Example format:
{{
    "categories": "category"
}}

Output ONLY valid JSON, nothing else.
"""

    try:
        response = client.chat.completions.create(
            model="llama3.2",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=30,
        )
        
        # Parse JSON response
        content = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
            content = content.strip()
        
        data = json.loads(content)
        
        return ExtractionResponse(
            categories=data.get("categories", "")
        )
    except Exception as e:
        print(f"Error extracting categories: {e}")
        return ExtractionResponse(categories="")


def ai_evaluate_sentiment(cleaned_comment: str) -> SentimentResponse:
    """
    Uses AI to evaluate both sentiment score and label.
    """
    prompt = f"""You are a neutral sentiment evaluator.  
Given a professionally rewritten comment, assign BOTH a sentiment score (1-10) AND a sentiment label (negative, neutral, or positive).

Analyze the comment's tone, emotion, and overall sentiment to determine:
1. A sentiment score from 1 to 10
2. A sentiment label that best represents the overall sentiment

Scoring Guidelines:
1-2: Extremely negative
3-4: Negative
5-6: Neutral
7-8: Positive
9-10: Very positive

Label Guidelines:
- "negative": Comment expresses dissatisfaction, complaints, frustration, or concerns
- "neutral": Comment is factual, balanced, or mixed with no strong emotion
- "positive": Comment expresses satisfaction, appreciation, or positive experiences

Comment: "{cleaned_comment}"

Respond ONLY in JSON:
{{
  "sentiment_score": <number 0-1>,
  "sentiment_label": "<negative|neutral|positive>"
}}
"""

    try:
        response = client.chat.completions.create(
            model="llama3.2",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=50,
        )
        
        # Parse JSON response
        content = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
            content = content.strip()
        
        data = json.loads(content)
        
        return SentimentResponse(
            sentiment_score=data.get("sentiment_score", 5),
            sentiment_label=data.get("sentiment_label", "neutral")
        )
    except Exception as e:
        print(f"Error evaluating sentiment: {e}")
        return SentimentResponse(sentiment_score=5, sentiment_label="neutral")


# ==================== Global Model Caching ====================
_corrector = None
_transformer = None

def load_models():
    """Lazy load Malaya models to avoid reloading on every request"""
    global _corrector, _transformer
    
    if _corrector is None:
        print("Loading Malaya Normalizer...")
        try:
            _corrector = malaya.normalize.normalizer(date=False, time=False, money=False)
        except AttributeError:
            _corrector = malaya.normalizer.rules.normalizer(date=False, time=False, money=False)
            
    if _transformer is None:
        print("Loading Malaya MS->EN Transformer...")
        _transformer = malaya.translation.huggingface(
            model='mesolitica/translation-t5-base-standard-bahasa-cased'
        )

# ==================== Processing Logic ====================

def process_single_comment(original_text: str) -> dict:
    """
    Process a single comment through the full NLP pipeline.
    """
    # Handle empty comments
    if not original_text or not isinstance(original_text, str) or not original_text.strip():
        return CommentAnalysis(
            original=original_text or "",
            rephrased="",
            categories="",
            sentiment_score=5,
            sentiment_label="neutral"
        ).model_dump()
        
    # Ensure models are loaded
    load_models()
    
    try:
        # 1. Normalize using Malaya
        normalized_dict = _corrector.normalize(original_text)
        normalized_text = normalized_dict['normalize']
        
        # 2. Translate using Malaya (MS -> EN)
        translated_text = _transformer.generate([normalized_text], to_lang='en')[0]
        
        # 3. Rephrase using AI (maintaining meaning)
        rephrased_text = ai_rephrase(original_text, translated_text)
        
        # 4. Extract categories using AI
        extraction = ai_extract_categories(rephrased_text)
        
        # 5. Evaluate sentiment (AI now determines both score and label)
        sentiment = ai_evaluate_sentiment(rephrased_text)
        
        # 6. Create structured output
        analysis = CommentAnalysis(
            original=original_text,
            rephrased=rephrased_text,
            categories=extraction.categories,
            sentiment_score=sentiment.sentiment_score,
            sentiment_label=sentiment.sentiment_label
        )
        
        return analysis.model_dump()
        
    except Exception as e:
        print(f"Error processing comment: {e}")
        # Return fallback on error
        return CommentAnalysis(
            original=original_text,
            rephrased=original_text, # Fallback to original
            categories="Error",
            sentiment_score=5,
            sentiment_label="neutral"
        ).model_dump()

def combined_nlp_pipeline(df_path: str) -> str:
    """
    Complete NLP pipeline that processes a CSV file.
    """
    try:
        # ===== STEP 1: Load Data =====
        df = pd.read_csv(df_path)
        if "Comments" not in df.columns:
            return json.dumps({"error": "Column 'Comments' not found"})
        
        # Take top 4 rows
        df_subset = df.head(4).copy()
        
        # ===== STEP 2: Process Each Comment =====
        results = []
        
        for original_text in df_subset['Comments']:
            analysis_dict = process_single_comment(original_text)
            results.append(analysis_dict)
        
        # ===== STEP 3: Return JSON Output =====
        return json.dumps(results, indent=5, ensure_ascii=False)
    
    except FileNotFoundError:
        return json.dumps({"error": "File not found"})
    except Exception as e:
        return json.dumps({"error": str(e)})


# ==================== Example Usage ====================

if __name__ == "__main__":
    # Test single function
    print("\n--- Single Test ---")
    single_res = process_single_comment("Kerja ni penat gila tapi member best")
    print(single_res)
